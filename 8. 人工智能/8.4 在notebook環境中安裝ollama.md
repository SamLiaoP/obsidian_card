
### Install ollama
```
Project Github Repo: https://github.com/ollama/ollama
!curl https://ollama.ai/install.sh | sh
```

### Ollama serve in the background
```
!nohup ollama serve &
```

### Ollama pull model
```
!ollama pull cwchang/llama-3-taiwan-8b-instruct
```


### test ollama
```
!ollama run cwchang/llama-3-taiwan-8b-instruct "請使用繁體中文，介紹 llama-3-taiwan LLM 模型？"
```


### install python ollama
```
!pip install -q ollama
```

```
import ollama
response = ollama.chat(model='cwchang/llama-3-taiwan-8b-instruct', messages=[
{
'role': 'user',
'content': '為什麼天空是藍色的？',
},
])
print(response['message']['content'])
```
