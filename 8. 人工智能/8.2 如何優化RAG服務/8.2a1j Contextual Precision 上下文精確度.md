
## LLM as a judge  

## Required
- User Input
- LLM Output
- Retrieval Context
- Ground True

## 描述
**上下文精確度**評估 RAG 流程中檢索器的表現，判斷檢索到的上下文中相關內容是否比不相關的內容更高排名。此指標強調將相關的檢索結果放在前列的重要性，因為這會影響 LLM 的生成效果。**ContextualPrecisionMetric** 會產生詳細的評分理由，說明分數的來源。

## 計算方法
上下文精確度使用加權累積精確度 (Weighted Cumulative Precision, WCP) 進行計算，強調前列結果的重要性。計算公式如下：

$$
\text{Contextual Precision} = \frac{1}{\text{Number of Relevant Nodes}} \sum_{k=1}^{n} \left( \frac{\text{Number of Relevant Nodes Up to Position } k}{k} \times r_k \right)
$$

其中：
- \( k \) 是檢索上下文中的位置。
- \( n \) 是檢索上下文的總長度。
- \( r_k \) 是二元相關性指標，若第 \( k \) 個檢索結果相關則 \( r_k = 1 \)，不相關則 \( r_k = 0 \)。

**WCP** 通過加權方式確保高相關性結果更靠前，並獎勵優先排序的相關內容。

## 程式碼
```python
from deepeval import evaluate
from deepeval.metrics import ContextualPrecisionMetric
from deepeval.test_case import LLMTestCase

# 生成的回應
actual_output = "We offer a 30-day full refund at no extra cost."

# 預期的回應
expected_output = "You are eligible for a 30 day full refund at no extra cost."

# 檢索上下文
retrieval_context = ["All customers are eligible for a 30 day full refund at no extra cost."]

# 初始化上下文精確度評分器並設置參數
metric = ContextualPrecisionMetric(
    threshold=0.7,
    model="gpt-4",
    include_reason=True
)

# 設置測試案例
test_case = LLMTestCase(
    input="What if these shoes don't fit?",
    actual_output=actual_output,
    expected_output=expected_output,
    retrieval_context=retrieval_context
)

# 計算上下文精確度分數
metric.measure(test_case)
print("Contextual Precision Score:", metric.score)
print("Explanation:", metric.reason)
```

在此範例中，**Contextual Precision Score** 表示系統對相關上下文的排序能力，`Explanation` 提供詳細解釋。高分數表明檢索系統能將相關上下文片段排名靠前，有助於提高生成回應的質量。

## 參考資料:
https://chatgpt.com/c/6721a817-804c-8005-88ac-520c1854e94b