## LLM as a judge  

## Required
- User Input
- Retrieved Contexts

## 描述
**上下文精確性**衡量檢索到的上下文片段中有多大比例與用戶查詢相關。此分數基於每個檢索片段的 **Precision@k**，計算回應中相關片段的平均比例。**Context Precision** 可通過多種方法計算，分為 LLM 基於模型的上下文精確性評估和非 LLM 基於模型的傳統方法。

### 計算方法
上下文精確性計算過程如下：
1. **計算 Precision@k**：每個片段在檢索結果中的排名 \( k \) 下，相關片段數量占總片段數的比例。
2. **上下文精確性**：對所有片段的 Precision@k 取平均，以獲得上下文精確性分數。

### LLM 基於模型的上下文精確性
- **LLMContextPrecisionWithoutReference**：適用於有檢索上下文但無參考答案的情況，透過 LLM 將檢索片段與生成回應比對。
- **LLMContextPrecisionWithReference**：適用於有檢索上下文和參考答案的情況，透過 LLM 比較檢索片段和參考答案。

## 程式碼

### 1. LLMContextPrecisionWithoutReference
```python
from ragas import SingleTurnSample
from ragas.metrics import LLMContextPrecisionWithoutReference

# 初始化上下文精確性計分器
context_precision = LLMContextPrecisionWithoutReference()

sample = SingleTurnSample(
    user_input="Where is the Eiffel Tower located?",
    response="The Eiffel Tower is located in Paris.",
    retrieved_contexts=["The Eiffel Tower is located in Paris."]
)

# 計算上下文精確性分數
await context_precision.single_turn_ascore(sample)
```

## 參考資料：
https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_precision/?h=context