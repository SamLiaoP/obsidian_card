## LLM as a judge  

## Required
- User Input
- LLM Output

## 描述
**摘要**指標使用 LLM 來評估生成的摘要是否正確地包含原始文本中的必要細節，並且事實上是正確的。此指標著重於檢查摘要內容是否與原始文本一致，並且沒有幻覺或矛盾訊息，並且包括所有必要的資訊。**SummarizationMetric** 是非快取的指標，需在每次測量時重新計算。

## 計算方法
摘要分數由以下兩個評估維度的最小值決定：

$$
\text{Summarization} = \min(\text{Alignment Score}, \text{Coverage Score})
$$

- **Alignment Score**：確保摘要內容不包含幻覺或與原文矛盾的訊息。
- **Coverage Score**：確認摘要涵蓋了原文中的必要資訊。使用閉合問題（答案為「是」或「否」的問題）來計算此分數，並通過計算原文和摘要在問題上的一致回答比例來獲得。

若其中任一分數為 0，最終的摘要分數也將為 0。

## 程式碼
```python
from deepeval import evaluate
from deepeval.metrics import SummarizationMetric
from deepeval.test_case import LLMTestCase

# 原始文本
input_text = """
The 'coverage score' is calculated as the percentage of assessment questions
for which both the summary and the original document provide a 'yes' answer. This
method ensures that the summary not only includes key information from the original
text but also accurately represents it. A higher coverage score indicates a
more comprehensive and faithful summary, signifying that the summary effectively
encapsulates the crucial points and details from the original content.
"""

# 生成的摘要
actual_output = """
The coverage score quantifies how well a summary captures and
accurately represents key information from the original text,
with a higher score indicating greater comprehensiveness.
"""

# 設定測試案例
test_case = LLMTestCase(input=input_text, actual_output=actual_output)
metric = SummarizationMetric(
    threshold=0.5,
    model="gpt-4",
    assessment_questions=[
        "Is the coverage score based on a percentage of 'yes' answers?",
        "Does the score ensure the summary's accuracy with the source?",
        "Does a higher score mean a more comprehensive summary?"
    ]
)

# 計算摘要分數
metric.measure(test_case)
print("Summarization Score:", metric.score)
print("Explanation:", metric.reason)
print("Score Breakdown:", metric.score_breakdown)
```

在這段程式碼中，`Summarization Score` 為對齊分數和涵蓋分數的最小值。


## 參考資料：
https://docs.confident-ai.com/docs/metrics-summarization