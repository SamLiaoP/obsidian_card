
## LLM as a judge  

## Required
- User Input  -> Question
- LLM Output -> Response

## 描述
**回應相關性**用於評估生成的回應是否直接針對用戶問題，並避免無關的額外資訊。此分數衡量回應對於問題的專注程度，確保生成的回應不偏離問題主題。

## 計算方法
回應相關性通過以下兩步評估：

1. **檢查直接回答**：確認回應內容是否與問題直接相關。
2. **識別無關資訊**：檢查回應中是否包含與問題無關的多餘資訊。

回應得分越高表示其越專注於回答問題，無多餘的無關內容。

## 程式碼
```python
from uptrain import EvalLLM, Evals

# 插入您的 OpenAI API 密鑰
OPENAI_API_KEY = "sk-********************"

data = [{
    "question": "What are the benefits of regular exercise?",
    "response": "Regular exercise has well-documented health benefits. On a related note, the importance of routine health check-ups in preventive healthcare cannot be emphasized enough. It allows for early detection of potential health issues and facilitates proactive management for individuals."
}]

# 初始化回應相關性評估
eval_llm = EvalLLM(openai_api_key=OPENAI_API_KEY)

# 計算回應相關性分數
res = eval_llm.evaluate(
    data = data,
    checks = [Evals.RESPONSE_RELEVANCE]
)

print(res)
```

範例輸出：
```json
[
   {
      "score_response_relevance": 0.0,
      "explanation_response_relevance": "The LLM response contains a lot of additional irrelevant information because it goes off on a tangent about routine health check-ups and preventive healthcare, which is not directly related to the benefits of regular exercise. This additional information distracts from the main topic and does not directly address the user query."
   }
]
```

在此範例中，回應包含無關於問題的資訊，導致較低的回應相關性分數。`Explanation` 詳細解釋了無關內容的來源。