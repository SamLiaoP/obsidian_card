{
  "file_id": "cc594c43",
  "name": "8.2a1j Contextual Precision 上下文精確度.md",
  "path": "8. 人工智能/8.2 如何優化RAG服務/8.2a1j Contextual Precision 上下文精確度.md",
  "content": "\n## LLM as a judge  \n\n## Required\n- User Input\n- LLM Output\n- Retrieval Context\n- Ground True\n\n## 描述\n**上下文精確度**評估 RAG 流程中檢索器的表現，判斷檢索到的上下文中相關內容是否比不相關的內容更高排名。此指標強調將相關的檢索結果放在前列的重要性，因為這會影響 LLM 的生成效果。**ContextualPrecisionMetric** 會產生詳細的評分理由，說明分數的來源。\n\n## 計算方法\n上下文精確度使用加權累積精確度 (Weighted Cumulative Precision, WCP) 進行計算，強調前列結果的重要性。計算公式如下：\n\n$$\n\\text{Contextual Precision} = \\frac{1}{\\text{Number of Relevant Nodes}} \\sum_{k=1}^{n} \\left( \\frac{\\text{Number of Relevant Nodes Up to Position } k}{k} \\times r_k \\right)\n$$\n\n其中：\n- \\( k \\) 是檢索上下文中的位置。\n- \\( n \\) 是檢索上下文的總長度。\n- \\( r_k \\) 是二元相關性指標，若第 \\( k \\) 個檢索結果相關則 \\( r_k = 1 \\)，不相關則 \\( r_k = 0 \\)。\n\n**WCP** 通過加權方式確保高相關性結果更靠前，並獎勵優先排序的相關內容。\n\n## 程式碼\n```python\nfrom deepeval import evaluate\nfrom deepeval.metrics import ContextualPrecisionMetric\nfrom deepeval.test_case import LLMTestCase\n\n# 生成的回應\nactual_output = \"We offer a 30-day full refund at no extra cost.\"\n\n# 預期的回應\nexpected_output = \"You are eligible for a 30 day full refund at no extra cost.\"\n\n# 檢索上下文\nretrieval_context = [\"All customers are eligible for a 30 day full refund at no extra cost.\"]\n\n# 初始化上下文精確度評分器並設置參數\nmetric = ContextualPrecisionMetric(\n    threshold=0.7,\n    model=\"gpt-4\",\n    include_reason=True\n)\n\n# 設置測試案例\ntest_case = LLMTestCase(\n    input=\"What if these shoes don't fit?\",\n    actual_output=actual_output,\n    expected_output=expected_output,\n    retrieval_context=retrieval_context\n)\n\n# 計算上下文精確度分數\nmetric.measure(test_case)\nprint(\"Contextual Precision Score:\", metric.score)\nprint(\"Explanation:\", metric.reason)\n```\n\n在此範例中，**Contextual Precision Score** 表示系統對相關上下文的排序能力，`Explanation` 提供詳細解釋。高分數表明檢索系統能將相關上下文片段排名靠前，有助於提高生成回應的質量。\n\n## 參考資料:\nhttps://chatgpt.com/c/6721a817-804c-8005-88ac-520c1854e94b",
  "size": 1713,
  "lines": 66
}